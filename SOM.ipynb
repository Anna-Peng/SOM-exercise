{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SOM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOpUEyeGzK/NsR5mkurSYAm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anna-Peng/SOM-exercise/blob/master/SOM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYffEOZUr7dK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/googlecolab/colabtools/Anna-Peng/SOM-exercise/blob/master/SOM.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import numpy as np # This package deals with matrix and array\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "data_dim = 12 # the number of dimensions\n",
        "data_no = 300 # Number of data sample (divisable by 3 groups)\n",
        "n_iteration=[5000, 8000, 12000] # the script will loop through different no. of training iterations\n",
        "lrate = 0.07 # learning rate, the value will decrease with iteration\n",
        "group_diff = [[0, 1], [3], [4, 5]] # these specific dimensions that make a unique group\n",
        "training_no = data_no\n",
        "\n",
        "\n",
        "'''\n",
        "Generate random data sample\n",
        "'''\n",
        "raw_data = [np.random.random(data_dim) for i in range(data_no)] # Generate data samples\n",
        "n_group = int(data_no/len(group_diff)) # number of sample in each group\n",
        "group_index = [range(0, n_group-1), range(n_group, 2*n_group-1), range(2*n_group, 3*n_group-1)]\n",
        "\n",
        "for i, ii, iii in zip(group_index[0], group_index[1], group_index[2]): # Coerce group indices\n",
        "        raw_data[i][group_diff[0]]   = 0.01 #[1 if a < 0.5 else a for a in raw_data[i][group_diff[0]] ]\n",
        "        raw_data[ii][group_diff[1]]  = 0.01 #[1 if a < 0.5 else a for a in raw_data[ii][group_diff[1]] ]\n",
        "        raw_data[iii][group_diff[2]] = 0.01 #[1 if a < 0.5 else a for a in raw_data[iii][group_diff[2]] ]   \n",
        "\n",
        "'''\n",
        "Construct Network\n",
        "'''    \n",
        "n_node=17 # network size (square) rule of thumb M= 5*sqrt(dim)\n",
        "net = np.random.random((n_node, n_node, data_dim)) # Random weight matrix\n",
        "init_rad= n_node/2  # initiate neighborhood size to 1/2 of grid space, this will gradually decrease, can be of different values \n",
        "\n",
        "'''\n",
        "Define functions\n",
        "'''\n",
        "\n",
        "def radius_update(init_rad, timer, norm_it): # this function reduces the current neighborhood radius\n",
        "    return init_rad * np.exp( - timer / norm_it)\n",
        "\n",
        "def eta_update(lrate, timer, iteration): # This function reduces learning rate\n",
        "    return lrate * np.exp( - timer / iteration)\n",
        "    \n",
        "def calculate_influence(distance, curr_rad): # This function determines a larger influence to closer node to bmu\n",
        "    return np.exp(-distance / (2* (curr_rad**2))) # i.e. smaller influence to distant node\n",
        "\n",
        "def find_bmu(v, net): # Find best matching unit, v is one training data sample    \n",
        "    bmu_id = np.array([0, 0]) # initiate empty bmu_id\n",
        "    # initiate a large number for the greatest possible manhatten distance (distance--diff bt data sample and weight vector), the value is a computer-defined number. \n",
        "    # This computer-based number can be used for non-normalised data where the distance can be large  \n",
        "    min_dist = np.iinfo(np.int).max \n",
        "    for i in range(n_node):\n",
        "        for j in range(n_node):\n",
        "            W = net[i, j, :] # node weights to all dimensional nodes \n",
        "            # Calculate manhatten Distance bt weight vector and input vector\n",
        "            # Manhattan distance. Definition: The distance between two points measured along axes at right angles. \n",
        "            # it is |x1 - x2| + |y1 - y2|\n",
        "            curr_dist = np.sum(abs(W - v)) \n",
        "            if curr_dist < min_dist:\n",
        "                    min_dist = curr_dist\n",
        "                    bmu_id = np.array([i, j]) # record which node is the best-matching unit\n",
        "    bmu_w = net[bmu_id[0], bmu_id[1], :] # Get the weight vector for the bmu\n",
        "    return (bmu_w, bmu_id) # bmu_w is the weight vector to the bmu unit\n",
        "    \n",
        "def move_neighbour(v, bmu_id, net, curr_rad, curr_lrate): # This function finds the neighbors and update the weights\n",
        "    for x in range(net.shape[0]):\n",
        "        for y in range(net.shape[1]):\n",
        "            W = net[x, y, :] # input-node weight vector\n",
        "            w_dis = np.sum(abs(np.array([x, y]) - bmu_id)) # w_dist for all neighboring nodes\n",
        "            if w_dis <= curr_rad:\n",
        "                influence = calculate_influence(w_dis, curr_rad)\n",
        "                new_w = W + (curr_lrate * influence * (v - W)) # if unit in v is smaller than unit in W, weight is reduced\n",
        "                net[x, y, :] = new_w\n",
        "    return net\n",
        "\n",
        "\n",
        "curr_rad = init_rad\n",
        "curr_lrate = lrate\n",
        "\n",
        "'''\n",
        "Running the net with for loop in n_iteration\n",
        "'''\n",
        "for iteration in n_iteration:\n",
        "    norm_it = iteration / np.log(init_rad) # this allows neighborhood to decay to 1 with iteration time\n",
        "    for timer in range(iteration):\n",
        "            train_v=raw_data[np.random.randint(1,training_no)]\n",
        "            bmu_w, bmu_id = find_bmu(train_v, net)\n",
        "            trained_net = move_neighbour(train_v, bmu_id, net, curr_rad, curr_lrate)\n",
        "            curr_rad = radius_update(init_rad, timer, norm_it)\n",
        "            curr_lrate = eta_update(lrate, timer, iteration)\n",
        "            \n",
        "\n",
        "    \n",
        "    '''\n",
        "    Plotting\n",
        "    '''\n",
        "    \n",
        "    def euc_dist(v1, v2):\n",
        "        return np.linalg.norm(v1 - v2) \n",
        "    \n",
        "    Rows=n_node\n",
        "    Cols=n_node\n",
        "    \n",
        "    print(\"Constructing U-Matrix from SOM, Data: {3}, Net: {0}, Dim: {1}, It: {2}\".format(n_node, data_dim, iteration, data_no))\n",
        "    u_matrix = np.zeros(shape=(Rows, Cols), dtype=np.float64)\n",
        "    \n",
        "    for i in range(Rows):\n",
        "        for j in range(Cols):\n",
        "            v = trained_net[i][j]  # matrix to input unit vector\n",
        "            sum_dists = 0.0; ct = 0 # ct counter\n",
        "            if i-1 >= 0:    # above\n",
        "                sum_dists += euc_dist(v, trained_net[i-1][j]); ct += 1\n",
        "            if i+1 <= Rows-1:   # below\n",
        "                sum_dists += euc_dist(v, trained_net[i+1][j]); ct += 1\n",
        "            if j-1 >= 0:   # left\n",
        "                sum_dists += euc_dist(v, trained_net[i][j-1]); ct += 1\n",
        "            if j+1 <= Cols-1:   # right\n",
        "                sum_dists += euc_dist(v, trained_net[i][j+1]); ct += 1\n",
        "            u_matrix[i][j] = sum_dists / ct\n",
        "            \n",
        "    plt.imshow(u_matrix, cmap='gray')  # black = close = clusters\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "for i in range(0,data_dim):\n",
        "    print(\"Dimension: {}\".format(i))\n",
        "    plt.imshow(trained_net[:,:,i], cmap='gray')\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}